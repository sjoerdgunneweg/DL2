{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY8iX-eLYepQ"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jM6GveIUIlW",
        "outputId": "92e2b6d9-9d42-4dc5-dd44-33b19d9a52d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-evdcknr_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-evdcknr_\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting scipy\n",
            "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting ftfy\n",
            "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting regex\n",
            "  Using cached regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch\n",
            "  Using cached torch-2.7.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting einops\n",
            "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pyrender==0.1.45\n",
            "  Using cached pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting trimesh==3.9.34\n",
            "  Using cached trimesh-3.9.34-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pycollada==0.6\n",
            "  Using cached pycollada-0.6.tar.gz (103 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: packaging in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from clip==1.0) (25.0)\n",
            "Collecting torchvision (from clip==1.0)\n",
            "  Using cached torchvision-0.22.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting freetype-py (from pyrender==0.1.45)\n",
            "  Using cached freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting imageio (from pyrender==0.1.45)\n",
            "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting networkx (from pyrender==0.1.45)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from pyrender==0.1.45) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from pyrender==0.1.45) (11.2.1)\n",
            "Collecting pyglet>=1.4.10 (from pyrender==0.1.45)\n",
            "  Using cached pyglet-2.1.6-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting PyOpenGL==3.1.0 (from pyrender==0.1.45)\n",
            "  Using cached PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: six in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from pyrender==0.1.45) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from trimesh==3.9.34) (80.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from pycollada==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: wcwidth in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from ftfy) (0.2.13)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Using cached triton-3.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "Using cached trimesh-3.9.34-py3-none-any.whl (638 kB)\n",
            "Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Using cached regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached torch-2.7.0-cp39-cp39-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/201.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:43\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
            "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
            "    self.__buf.write(data)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/tempfile.py\", line 494, in func_wrapper\n",
            "    return func(*args, **kwargs)\n",
            "OSError: [Errno 28] No space left on device\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 105, in _run_wrapper\n",
            "    status = _inner_run()\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 96, in _inner_run\n",
            "    return self.run(options, args)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 68, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 387, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 182, in resolve\n",
            "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 559, in prepare_linked_requirements_more\n",
            "    self._complete_partial_requirements(\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 474, in _complete_partial_requirements\n",
            "    for link, (filepath, _) in batch_download:\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 313, in __call__\n",
            "    filepath, content_type = self._downloader(link, location)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 185, in __call__\n",
            "    bytes_received = self._process_response(\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 208, in _process_response\n",
            "    return self._write_chunks_to_file(\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 218, in _write_chunks_to_file\n",
            "    for chunk in chunks:\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 61, in _rich_download_progress_bar\n",
            "    for chunk in iterable:\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 65, in response_chunks\n",
            "    for chunk in response.raw.stream(\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/home/rfigge/.conda/envs/DL2test/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
            "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
            "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install scipy ftfy regex tqdm torch git+https://github.com/openai/CLIP.git einops pyrender==0.1.45 trimesh==3.9.34 pycollada==0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGIz2RohYkJ9"
      },
      "source": [
        "### Clone Repo and Setup\n",
        "\n",
        "Clone [https://github.com/peract/peract_colab.git](github.com/peract/peract_colab.git).   \n",
        "\n",
        "This repo contains barebones code from [`ARM`](https://github.com/stepjam/ARM), [`YARR`](https://github.com/stepjam/YARR), [`PyRep`](https://github.com/stepjam/PyRep), [`RLBench`](https://github.com/stepjam/RLBench) to get started with  PerAct without the actual [V-REP](https://www.coppeliarobotics.com/) simulator.\n",
        "\n",
        "The repo also contains a pre-generated RLBench dataset of 10 expert demonstrations for the `open_drawer` task. This task has three variations: \"open the top drawer\", \"open the middle drawer\", and \"open the bottom drawer\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJU62Vd5kJ99",
        "outputId": "4921517a-0bf7-443a-923b-0e50c0fa2525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'peract_colab' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/peract/peract_colab.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avT7JfBKc3Ya"
      },
      "source": [
        "If you fork-off this repo, you might want to pull the latest changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cERy2oElEuT",
        "outputId": "5580cb61-63f6-447c-fd9b-a5a394a60c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/peract/peract_colab\n",
            " * branch              master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd peract_colab && git pull origin master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wchWWR0k0ufw"
      },
      "source": [
        "Set `PYOPENGL_PLATFORM=egl` for pyrender visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCQorAMoc2Jh"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     25\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmast3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmast3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsymmetricMASt3R\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmast3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsymmetricCroCo3DStereo\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmast3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmast3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfast_nn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fast_reciprocal_NNs\n",
            "File \u001b[0;32m~/Documents/UVA/DL2/DL2/rubensklooisels/../mast3r/mast3r/model.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2024-present Naver Corporation. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# MASt3R model class\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.bool = np.bool_ # bad trick to fix numpy version issue :(\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "os.environ[\"DISPLAY\"] = \":0\"\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from mast3r.mast3r.model import AsymmetricMASt3R\n",
        "from mast3r.dust3r.model import AsymmetricCroCo3DStereo\n",
        "from mast3r.mast3r.fast_nn import fast_reciprocal_NNs\n",
        "\n",
        "import mast3r.mast3r.utils.path_to_dust3r\n",
        "from mast3r.dust3r.inference import inference\n",
        "from mast3r.dust3r.image_pairs import make_pairs\n",
        "from mast3r.dust3r.utils.device import to_numpy\n",
        "from mast3r.dust3r.demo import get_3D_model_from_scene\n",
        "from mast3r.dust3r.cloud_opt import global_aligner, GlobalAlignerMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tvf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ImgNorm \u001b[38;5;241m=\u001b[39m \u001b[43mtvf\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([tvf\u001b[38;5;241m.\u001b[39mToTensor(), tvf\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_resize_pil_image\u001b[39m(img, long_edge_size):\n\u001b[1;32m      4\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(img\u001b[38;5;241m.\u001b[39msize)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tvf' is not defined"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as tvf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "ImgNorm = tvf.Compose([\n",
        "    tvf.ToTensor(),\n",
        "    tvf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "def rgb(ftensor, true_shape=None):\n",
        "    if isinstance(ftensor, list):\n",
        "        return [rgb(x, true_shape=true_shape) for x in ftensor]\n",
        "    if isinstance(ftensor, torch.Tensor):\n",
        "        ftensor = ftensor.detach().cpu().numpy()  # H,W,3\n",
        "    if ftensor.ndim == 3 and ftensor.shape[0] == 3:\n",
        "        ftensor = ftensor.transpose(1, 2, 0)\n",
        "    elif ftensor.ndim == 4 and ftensor.shape[1] == 3:\n",
        "        ftensor = ftensor.transpose(0, 2, 3, 1)\n",
        "    if true_shape is not None:\n",
        "        H, W = true_shape\n",
        "        ftensor = ftensor[:H, :W]\n",
        "    if ftensor.dtype == np.uint8:\n",
        "        img = np.float32(ftensor) / 255\n",
        "    else:\n",
        "        img = (ftensor * 0.5) + 0.5\n",
        "    return img.clip(min=0, max=1)\n",
        "\n",
        "\n",
        "def _resize_pil_image(img, long_edge_size):\n",
        "    S = max(img.size)\n",
        "    interp = Image.LANCZOS if S > long_edge_size else Image.BICUBIC\n",
        "    new_size = tuple(int(round(x * long_edge_size / S)) for x in img.size)\n",
        "    return img.resize(new_size, interp)\n",
        "\n",
        "def load_images_from_loaded(images, size, square_ok=False, verbose=True):\n",
        "    \"\"\"\n",
        "    Process a list of already loaded images (as PIL.Image or NumPy arrays)\n",
        "    and convert them to normalized tensors for DUSt3R.\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f'>> Processing {len(images)} already-loaded images')\n",
        "\n",
        "    imgs = []\n",
        "    for idx, img in enumerate(images):\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = Image.fromarray(img)\n",
        "        elif not isinstance(img, Image.Image):\n",
        "            raise TypeError(f\"Unsupported image type at index {idx}: {type(img)}\")\n",
        "\n",
        "        img = img.convert('RGB')  # ensure RGB\n",
        "        W1, H1 = img.size\n",
        "\n",
        "        # Resize\n",
        "        if size == 224:\n",
        "            img = _resize_pil_image(img, round(size * max(W1/H1, H1/W1)))\n",
        "        else:\n",
        "            img = _resize_pil_image(img, size)\n",
        "\n",
        "        # Center crop\n",
        "        W, H = img.size\n",
        "        cx, cy = W // 2, H // 2\n",
        "        if size == 224:\n",
        "            half = min(cx, cy)\n",
        "            img = img.crop((cx - half, cy - half, cx + half, cy + half))\n",
        "        else:\n",
        "            halfw, halfh = ((2 * cx) // 16) * 8, ((2 * cy) // 16) * 8\n",
        "            if not square_ok and W == H:\n",
        "                halfh = int(3 * halfw / 4)\n",
        "            img = img.crop((cx - halfw, cy - halfh, cx + halfw, cy + halfh))\n",
        "\n",
        "        W2, H2 = img.size\n",
        "        if verbose:\n",
        "            print(f' - processed image {idx} with resolution {W1}x{H1} --> {W2}x{H2}')\n",
        "\n",
        "        imgs.append(dict(\n",
        "            img=ImgNorm(img)[None],\n",
        "            true_shape=np.int32([img.size[::-1]]),\n",
        "            idx=idx,\n",
        "            instance=str(idx)\n",
        "        ))\n",
        "\n",
        "    assert imgs, 'No valid images were processed'\n",
        "    if verbose:\n",
        "        print(f' (Successfully processed {len(imgs)} images)')\n",
        "    return imgs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmZg4Qgt1Bf3"
      },
      "source": [
        "Define some constants and setting variables.\n",
        "\n",
        "The `BATCH_SIZE` is 1 to fit the model on a single GPU. But you can play around with the voxel sizes and Transformer layers to increase this.  \n",
        "\n",
        "In the paper, we use `NUM_LATENTS=2048` by default, but smaller latents like `512` are also fine (see Appendix G)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qvkDxdGtgtk-"
      },
      "outputs": [],
      "source": [
        "#constants:\n",
        "CAMERAS = ['front', 'left_shoulder', 'right_shoulder', 'wrist']\n",
        "IMAGE_SIZE =  128  # 128x128 - if you want to use higher voxel resolutions like 200^3, you might want to regenerate the dataset with larger images\n",
        "DATA_FOLDER ='peract_colab/data'\n",
        "EPISODES_FOLDER = 'colab_dataset/open_drawer/all_variations/episodes'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttvy-2W12Dk6"
      },
      "source": [
        "Add `peract_colab` to the system path and make a directory for storing the replay buffer.  For now, we will store the replay buffer on disk to avoid memory issues with putting everthing on RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VZt5BxKgngP6"
      },
      "outputs": [],
      "source": [
        "sys.path.append('peract_colab')\n",
        "data_path = os.path.join(DATA_FOLDER, EPISODES_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rlbench.utils import get_stored_demo\n",
        "from rlbench.backend.utils import extract_obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_DATA_PATH = os.path.abspath(\"../../../DL2/rlbench - 0B2LlLwoO3nfZfkFqMEhXWkxBdjJNNndGYl9uUDQwS1pfNkNHSzFDNGwzd1NnTmlpZXR1bVE/test/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "task_dirs = os.listdir(TEST_DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "schedule = 'cosine'\n",
        "lr = 0.01\n",
        "niter = 300\n",
        "model_name = \"naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric\"\n",
        "model = AsymmetricMASt3R.from_pretrained(model_name).to(device)\n",
        "\n",
        "#Loop through all the tasks:\n",
        "for task_dir in task_dirs:\n",
        "    print(f\"Current task: {task_dir}\")\n",
        "    task_path = os.path.join(TEST_DATA_PATH, task_dir)\n",
        "    episodes = os.listdir(os.path.join(task_path, \"all_variations/episodes\"))\n",
        "\n",
        "    #Loop through all the episodes:\n",
        "    for episode_idx in range(len(episodes)):\n",
        "        print(f\"Current episode: {episode_idx}\")\n",
        "        episode_path = os.path.join(task_path, 'all_variations/episodes')\n",
        "        \n",
        "        demo = get_stored_demo(episode_path, episode_idx)\n",
        "\n",
        "        #Loop through time steps:\n",
        "        for ts in range(len(demo)):\n",
        "            obs_dict = extract_obs(demo._observations[ts], CAMERAS, t=ts)\n",
        "\n",
        "            images = load_images_from_loaded([obs_dict['front_rgb'], \n",
        "                                     obs_dict['left_shoulder_rgb'], \n",
        "                                     obs_dict['right_shoulder_rgb'], \n",
        "                                     obs_dict['wrist_rgb']], size=512, square_ok=True)\n",
        "            \n",
        "            pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
        "            output = inference(pairs, model, device, batch_size=1, verbose=False)\n",
        "\n",
        "            mode = GlobalAlignerMode.PointCloudOptimizer #if len(images) > 2 else GlobalAlignerMode.PairViewer\n",
        "            scene = global_aligner(output, device=device, mode=mode, verbose=False)\n",
        "            if mode == GlobalAlignerMode.PointCloudOptimizer:\n",
        "                loss = scene.compute_global_alignment(init='mst', niter=niter, schedule=schedule, lr=lr)\n",
        "\n",
        "            rgbimg = scene.imgs\n",
        "            depths = to_numpy(scene.get_depthmaps())\n",
        "            depths_max = max([d.max() for d in depths])\n",
        "            depths = [d / depths_max for d in depths]\n",
        "            print(depths[0])\n",
        "\n",
        "            imgs = []\n",
        "            for i in range(len(rgbimg)):\n",
        "                imgs.append(rgb(depths[i]))\n",
        "\n",
        "            # plot the depth of image 1 using 3d points:depth\n",
        "\n",
        "            plt.figure()\n",
        "            depth = Image.fromarray(imgs[0])\n",
        "            depth = depth.resize((128, 128), Image.LANCZOS)\n",
        "            plt.imshow(np.asarray(depth))\n",
        "            plt.savefig('test.pdf')\n",
        "            plt.show(block=True)\n",
        "            plt.figure()\n",
        "            depth = Image.fromarray(imgs[1])\n",
        "            depth = depth.resize((128, 128), Image.LANCZOS)\n",
        "            plt.imshow(np.asarray(depth))\n",
        "            plt.savefig('test1.pdf')\n",
        "            plt.show(block=True)\n",
        "            plt.figure()\n",
        "            depth = Image.fromarray(imgs[2])\n",
        "            depth = depth.resize((128, 128), Image.LANCZOS)\n",
        "            plt.imshow(np.asarray(depth))\n",
        "            plt.savefig('test2.pdf')\n",
        "            plt.show(block=True)\n",
        "            plt.figure()\n",
        "            depth = Image.fromarray(imgs[3])\n",
        "            depth = depth.resize((128, 128), Image.LANCZOS)\n",
        "            plt.imshow(np.asarray(depth))\n",
        "            plt.savefig('test3.pdf')\n",
        "            plt.show(block=True)\n",
        "            plt.figure()\n",
        "            depth = Image.fromarray(imgs[4])\n",
        "            depth = depth.resize((128, 128), Image.LANCZOS)\n",
        "            plt.imshow(np.asarray(depth))\n",
        "            plt.savefig('test4.pdf')\n",
        "            plt.show(block=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "DL2test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
